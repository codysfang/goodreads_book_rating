{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "np.random.seed(409782)\n",
    "label = \"rating_label\"\n",
    "random_state_const = 10987"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(f\"train_final.csv\")\n",
    "test = pd.read_csv(f\"test_final.csv\")\n",
    "\n",
    "train_y = train.pop(label)\n",
    "train_X = train\n",
    "test_y = test.pop(label)\n",
    "test_X = test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "def report(a, b):\n",
    "    reports = [\n",
    "                metrics.accuracy_score(a, b), \n",
    "                metrics.precision_score(a, b, average=\"macro\"),\n",
    "                metrics.recall_score(a, b, average=\"macro\"),\n",
    "                metrics.f1_score(a, b, average=\"macro\")\n",
    "               ]\n",
    "    return reports"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_penalty</th>\n",
       "      <th>param_C</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_accuracy</th>\n",
       "      <th>split1_test_accuracy</th>\n",
       "      <th>split2_test_accuracy</th>\n",
       "      <th>...</th>\n",
       "      <th>std_test_accuracy</th>\n",
       "      <th>rank_test_accuracy</th>\n",
       "      <th>split0_test_f1_macro</th>\n",
       "      <th>split1_test_f1_macro</th>\n",
       "      <th>split2_test_f1_macro</th>\n",
       "      <th>split3_test_f1_macro</th>\n",
       "      <th>split4_test_f1_macro</th>\n",
       "      <th>mean_test_f1_macro</th>\n",
       "      <th>std_test_f1_macro</th>\n",
       "      <th>rank_test_f1_macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>33.434180</td>\n",
       "      <td>10.717765</td>\n",
       "      <td>0.004281</td>\n",
       "      <td>0.001475</td>\n",
       "      <td>none</td>\n",
       "      <td>5.016667</td>\n",
       "      <td>{'penalty': 'none', 'C': 5.016666666666667}</td>\n",
       "      <td>0.702439</td>\n",
       "      <td>0.702710</td>\n",
       "      <td>0.701897</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001105</td>\n",
       "      <td>5</td>\n",
       "      <td>0.325656</td>\n",
       "      <td>0.348000</td>\n",
       "      <td>0.314734</td>\n",
       "      <td>0.308134</td>\n",
       "      <td>0.324444</td>\n",
       "      <td>0.324193</td>\n",
       "      <td>0.013538</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>28.076285</td>\n",
       "      <td>9.293157</td>\n",
       "      <td>0.003454</td>\n",
       "      <td>0.001731</td>\n",
       "      <td>none</td>\n",
       "      <td>3.05</td>\n",
       "      <td>{'penalty': 'none', 'C': 3.0500000000000003}</td>\n",
       "      <td>0.702439</td>\n",
       "      <td>0.702710</td>\n",
       "      <td>0.701897</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001105</td>\n",
       "      <td>5</td>\n",
       "      <td>0.325656</td>\n",
       "      <td>0.348000</td>\n",
       "      <td>0.314734</td>\n",
       "      <td>0.308134</td>\n",
       "      <td>0.324444</td>\n",
       "      <td>0.324193</td>\n",
       "      <td>0.013538</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13.014538</td>\n",
       "      <td>5.740987</td>\n",
       "      <td>0.004760</td>\n",
       "      <td>0.001279</td>\n",
       "      <td>l2</td>\n",
       "      <td>2.066667</td>\n",
       "      <td>{'penalty': 'l2', 'C': 2.066666666666667}</td>\n",
       "      <td>0.701897</td>\n",
       "      <td>0.703794</td>\n",
       "      <td>0.701355</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001745</td>\n",
       "      <td>2</td>\n",
       "      <td>0.318022</td>\n",
       "      <td>0.320357</td>\n",
       "      <td>0.309853</td>\n",
       "      <td>0.293788</td>\n",
       "      <td>0.316242</td>\n",
       "      <td>0.311652</td>\n",
       "      <td>0.009589</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16.175604</td>\n",
       "      <td>10.074756</td>\n",
       "      <td>0.004042</td>\n",
       "      <td>0.001398</td>\n",
       "      <td>l2</td>\n",
       "      <td>1.083333</td>\n",
       "      <td>{'penalty': 'l2', 'C': 1.0833333333333335}</td>\n",
       "      <td>0.703794</td>\n",
       "      <td>0.703252</td>\n",
       "      <td>0.705691</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002120</td>\n",
       "      <td>1</td>\n",
       "      <td>0.302096</td>\n",
       "      <td>0.342409</td>\n",
       "      <td>0.322671</td>\n",
       "      <td>0.295415</td>\n",
       "      <td>0.316265</td>\n",
       "      <td>0.315771</td>\n",
       "      <td>0.016485</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>22.364062</td>\n",
       "      <td>4.704636</td>\n",
       "      <td>0.003205</td>\n",
       "      <td>0.000688</td>\n",
       "      <td>l2</td>\n",
       "      <td>6.0</td>\n",
       "      <td>{'penalty': 'l2', 'C': 6.0}</td>\n",
       "      <td>0.702710</td>\n",
       "      <td>0.702439</td>\n",
       "      <td>0.701897</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000815</td>\n",
       "      <td>3</td>\n",
       "      <td>0.325751</td>\n",
       "      <td>0.341014</td>\n",
       "      <td>0.312957</td>\n",
       "      <td>0.305199</td>\n",
       "      <td>0.341691</td>\n",
       "      <td>0.325322</td>\n",
       "      <td>0.014644</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>22.987068</td>\n",
       "      <td>4.230719</td>\n",
       "      <td>0.002482</td>\n",
       "      <td>0.000299</td>\n",
       "      <td>none</td>\n",
       "      <td>1.083333</td>\n",
       "      <td>{'penalty': 'none', 'C': 1.0833333333333335}</td>\n",
       "      <td>0.702439</td>\n",
       "      <td>0.702710</td>\n",
       "      <td>0.701897</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001105</td>\n",
       "      <td>5</td>\n",
       "      <td>0.325656</td>\n",
       "      <td>0.348000</td>\n",
       "      <td>0.314734</td>\n",
       "      <td>0.308134</td>\n",
       "      <td>0.324444</td>\n",
       "      <td>0.324193</td>\n",
       "      <td>0.013538</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>11.912201</td>\n",
       "      <td>3.730333</td>\n",
       "      <td>0.003686</td>\n",
       "      <td>0.001487</td>\n",
       "      <td>l2</td>\n",
       "      <td>5.016667</td>\n",
       "      <td>{'penalty': 'l2', 'C': 5.016666666666667}</td>\n",
       "      <td>0.702981</td>\n",
       "      <td>0.699458</td>\n",
       "      <td>0.701626</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001523</td>\n",
       "      <td>10</td>\n",
       "      <td>0.300020</td>\n",
       "      <td>0.316151</td>\n",
       "      <td>0.315602</td>\n",
       "      <td>0.305785</td>\n",
       "      <td>0.330401</td>\n",
       "      <td>0.313592</td>\n",
       "      <td>0.010376</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>15.991449</td>\n",
       "      <td>9.288772</td>\n",
       "      <td>0.002442</td>\n",
       "      <td>0.000271</td>\n",
       "      <td>l2</td>\n",
       "      <td>4.033333</td>\n",
       "      <td>{'penalty': 'l2', 'C': 4.033333333333333}</td>\n",
       "      <td>0.702710</td>\n",
       "      <td>0.699187</td>\n",
       "      <td>0.701897</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001584</td>\n",
       "      <td>4</td>\n",
       "      <td>0.324962</td>\n",
       "      <td>0.317078</td>\n",
       "      <td>0.313260</td>\n",
       "      <td>0.304713</td>\n",
       "      <td>0.327440</td>\n",
       "      <td>0.317491</td>\n",
       "      <td>0.008199</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>22.168400</td>\n",
       "      <td>4.057173</td>\n",
       "      <td>0.003169</td>\n",
       "      <td>0.001072</td>\n",
       "      <td>none</td>\n",
       "      <td>4.033333</td>\n",
       "      <td>{'penalty': 'none', 'C': 4.033333333333333}</td>\n",
       "      <td>0.702439</td>\n",
       "      <td>0.702710</td>\n",
       "      <td>0.701897</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001105</td>\n",
       "      <td>5</td>\n",
       "      <td>0.325656</td>\n",
       "      <td>0.348000</td>\n",
       "      <td>0.314734</td>\n",
       "      <td>0.308134</td>\n",
       "      <td>0.324444</td>\n",
       "      <td>0.324193</td>\n",
       "      <td>0.013538</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>21.913335</td>\n",
       "      <td>3.871037</td>\n",
       "      <td>0.004536</td>\n",
       "      <td>0.001515</td>\n",
       "      <td>none</td>\n",
       "      <td>6.0</td>\n",
       "      <td>{'penalty': 'none', 'C': 6.0}</td>\n",
       "      <td>0.702439</td>\n",
       "      <td>0.702710</td>\n",
       "      <td>0.701897</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001105</td>\n",
       "      <td>5</td>\n",
       "      <td>0.325656</td>\n",
       "      <td>0.348000</td>\n",
       "      <td>0.314734</td>\n",
       "      <td>0.308134</td>\n",
       "      <td>0.324444</td>\n",
       "      <td>0.324193</td>\n",
       "      <td>0.013538</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time param_penalty  \\\n",
       "0      33.434180     10.717765         0.004281        0.001475          none   \n",
       "1      28.076285      9.293157         0.003454        0.001731          none   \n",
       "2      13.014538      5.740987         0.004760        0.001279            l2   \n",
       "3      16.175604     10.074756         0.004042        0.001398            l2   \n",
       "4      22.364062      4.704636         0.003205        0.000688            l2   \n",
       "5      22.987068      4.230719         0.002482        0.000299          none   \n",
       "6      11.912201      3.730333         0.003686        0.001487            l2   \n",
       "7      15.991449      9.288772         0.002442        0.000271            l2   \n",
       "8      22.168400      4.057173         0.003169        0.001072          none   \n",
       "9      21.913335      3.871037         0.004536        0.001515          none   \n",
       "\n",
       "    param_C                                        params  \\\n",
       "0  5.016667   {'penalty': 'none', 'C': 5.016666666666667}   \n",
       "1      3.05  {'penalty': 'none', 'C': 3.0500000000000003}   \n",
       "2  2.066667     {'penalty': 'l2', 'C': 2.066666666666667}   \n",
       "3  1.083333    {'penalty': 'l2', 'C': 1.0833333333333335}   \n",
       "4       6.0                   {'penalty': 'l2', 'C': 6.0}   \n",
       "5  1.083333  {'penalty': 'none', 'C': 1.0833333333333335}   \n",
       "6  5.016667     {'penalty': 'l2', 'C': 5.016666666666667}   \n",
       "7  4.033333     {'penalty': 'l2', 'C': 4.033333333333333}   \n",
       "8  4.033333   {'penalty': 'none', 'C': 4.033333333333333}   \n",
       "9       6.0                 {'penalty': 'none', 'C': 6.0}   \n",
       "\n",
       "   split0_test_accuracy  split1_test_accuracy  split2_test_accuracy  ...  \\\n",
       "0              0.702439              0.702710              0.701897  ...   \n",
       "1              0.702439              0.702710              0.701897  ...   \n",
       "2              0.701897              0.703794              0.701355  ...   \n",
       "3              0.703794              0.703252              0.705691  ...   \n",
       "4              0.702710              0.702439              0.701897  ...   \n",
       "5              0.702439              0.702710              0.701897  ...   \n",
       "6              0.702981              0.699458              0.701626  ...   \n",
       "7              0.702710              0.699187              0.701897  ...   \n",
       "8              0.702439              0.702710              0.701897  ...   \n",
       "9              0.702439              0.702710              0.701897  ...   \n",
       "\n",
       "   std_test_accuracy  rank_test_accuracy  split0_test_f1_macro  \\\n",
       "0           0.001105                   5              0.325656   \n",
       "1           0.001105                   5              0.325656   \n",
       "2           0.001745                   2              0.318022   \n",
       "3           0.002120                   1              0.302096   \n",
       "4           0.000815                   3              0.325751   \n",
       "5           0.001105                   5              0.325656   \n",
       "6           0.001523                  10              0.300020   \n",
       "7           0.001584                   4              0.324962   \n",
       "8           0.001105                   5              0.325656   \n",
       "9           0.001105                   5              0.325656   \n",
       "\n",
       "   split1_test_f1_macro  split2_test_f1_macro  split3_test_f1_macro  \\\n",
       "0              0.348000              0.314734              0.308134   \n",
       "1              0.348000              0.314734              0.308134   \n",
       "2              0.320357              0.309853              0.293788   \n",
       "3              0.342409              0.322671              0.295415   \n",
       "4              0.341014              0.312957              0.305199   \n",
       "5              0.348000              0.314734              0.308134   \n",
       "6              0.316151              0.315602              0.305785   \n",
       "7              0.317078              0.313260              0.304713   \n",
       "8              0.348000              0.314734              0.308134   \n",
       "9              0.348000              0.314734              0.308134   \n",
       "\n",
       "   split4_test_f1_macro  mean_test_f1_macro  std_test_f1_macro  \\\n",
       "0              0.324444            0.324193           0.013538   \n",
       "1              0.324444            0.324193           0.013538   \n",
       "2              0.316242            0.311652           0.009589   \n",
       "3              0.316265            0.315771           0.016485   \n",
       "4              0.341691            0.325322           0.014644   \n",
       "5              0.324444            0.324193           0.013538   \n",
       "6              0.330401            0.313592           0.010376   \n",
       "7              0.327440            0.317491           0.008199   \n",
       "8              0.324444            0.324193           0.013538   \n",
       "9              0.324444            0.324193           0.013538   \n",
       "\n",
       "   rank_test_f1_macro  \n",
       "0                   2  \n",
       "1                   2  \n",
       "2                  10  \n",
       "3                   8  \n",
       "4                   1  \n",
       "5                   2  \n",
       "6                   9  \n",
       "7                   7  \n",
       "8                   2  \n",
       "9                   2  \n",
       "\n",
       "[10 rows x 23 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "logistic_classifier = LogisticRegression(random_state=random_state_const, max_iter=10000)\n",
    "possible_hyperparams = {'penalty': ['l2', 'none'], 'C':[i for i in np.linspace(0.1, 6, 7)]}\n",
    "\n",
    "grid_search = RandomizedSearchCV(logistic_classifier, possible_hyperparams, n_iter = 10, scoring=['accuracy','f1_macro'], refit=False, random_state=623)\n",
    "grid_search.fit(train_X, train_y)\n",
    "\n",
    "results = pd.DataFrame(grid_search.cv_results_)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_class_weight</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_accuracy</th>\n",
       "      <th>split1_test_accuracy</th>\n",
       "      <th>split2_test_accuracy</th>\n",
       "      <th>split3_test_accuracy</th>\n",
       "      <th>...</th>\n",
       "      <th>std_test_accuracy</th>\n",
       "      <th>rank_test_accuracy</th>\n",
       "      <th>split0_test_f1_macro</th>\n",
       "      <th>split1_test_f1_macro</th>\n",
       "      <th>split2_test_f1_macro</th>\n",
       "      <th>split3_test_f1_macro</th>\n",
       "      <th>split4_test_f1_macro</th>\n",
       "      <th>mean_test_f1_macro</th>\n",
       "      <th>std_test_f1_macro</th>\n",
       "      <th>rank_test_f1_macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22.821954</td>\n",
       "      <td>2.083999</td>\n",
       "      <td>0.004328</td>\n",
       "      <td>0.001391</td>\n",
       "      <td>None</td>\n",
       "      <td>{'class_weight': None}</td>\n",
       "      <td>0.702439</td>\n",
       "      <td>0.704065</td>\n",
       "      <td>0.701897</td>\n",
       "      <td>0.701084</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001360</td>\n",
       "      <td>1</td>\n",
       "      <td>0.320396</td>\n",
       "      <td>0.345280</td>\n",
       "      <td>0.313490</td>\n",
       "      <td>0.309908</td>\n",
       "      <td>0.337696</td>\n",
       "      <td>0.325354</td>\n",
       "      <td>0.013808</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18.375476</td>\n",
       "      <td>4.216089</td>\n",
       "      <td>0.003620</td>\n",
       "      <td>0.001311</td>\n",
       "      <td>balanced</td>\n",
       "      <td>{'class_weight': 'balanced'}</td>\n",
       "      <td>0.408943</td>\n",
       "      <td>0.407046</td>\n",
       "      <td>0.394038</td>\n",
       "      <td>0.417344</td>\n",
       "      <td>...</td>\n",
       "      <td>0.008362</td>\n",
       "      <td>2</td>\n",
       "      <td>0.357552</td>\n",
       "      <td>0.353767</td>\n",
       "      <td>0.341713</td>\n",
       "      <td>0.364547</td>\n",
       "      <td>0.360527</td>\n",
       "      <td>0.355621</td>\n",
       "      <td>0.007802</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0      22.821954      2.083999         0.004328        0.001391   \n",
       "1      18.375476      4.216089         0.003620        0.001311   \n",
       "\n",
       "  param_class_weight                        params  split0_test_accuracy  \\\n",
       "0               None        {'class_weight': None}              0.702439   \n",
       "1           balanced  {'class_weight': 'balanced'}              0.408943   \n",
       "\n",
       "   split1_test_accuracy  split2_test_accuracy  split3_test_accuracy  ...  \\\n",
       "0              0.704065              0.701897              0.701084  ...   \n",
       "1              0.407046              0.394038              0.417344  ...   \n",
       "\n",
       "   std_test_accuracy  rank_test_accuracy  split0_test_f1_macro  \\\n",
       "0           0.001360                   1              0.320396   \n",
       "1           0.008362                   2              0.357552   \n",
       "\n",
       "   split1_test_f1_macro  split2_test_f1_macro  split3_test_f1_macro  \\\n",
       "0              0.345280              0.313490              0.309908   \n",
       "1              0.353767              0.341713              0.364547   \n",
       "\n",
       "   split4_test_f1_macro  mean_test_f1_macro  std_test_f1_macro  \\\n",
       "0              0.337696            0.325354           0.013808   \n",
       "1              0.360527            0.355621           0.007802   \n",
       "\n",
       "   rank_test_f1_macro  \n",
       "0                   2  \n",
       "1                   1  \n",
       "\n",
       "[2 rows x 22 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "logistic_classifier = LogisticRegression(random_state=random_state_const, max_iter=10000, penalty='l2', C=6)\n",
    "possible_hyperparams = {'class_weight':[None, 'balanced']}\n",
    "grid_search = GridSearchCV(logistic_classifier, possible_hyperparams, scoring=['accuracy','f1_macro'], refit=False)\n",
    "grid_search.fit(train_X, train_y)\n",
    "\n",
    "results = pd.DataFrame(grid_search.cv_results_)\n",
    "results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "logis = LogisticRegression(random_state=10987, max_iter=10000, penalty='l2', C=6)\n",
    "logis.fit(train_X, train_y)\n",
    "res = logis.predict(test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.7053977888575764,\n",
       " 0.6190928741800835,\n",
       " 0.3595447180727335,\n",
       " 0.33477359993836303]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "report(test_y, res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "cm = confusion_matrix(test_y, res)\n",
    "cmn = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "# Creating a dataframe for a array-formatted Confusion matrix,so it will be easy for plotting.\n",
    "cm_df = pd.DataFrame(cmn,\n",
    "                     index = ['3','4','5'], \n",
    "                     columns = ['3','4','5'])\n",
    "#Plotting the confusion matrix\n",
    "plt.figure(figsize=(5,4))\n",
    "sns.heatmap(cm_df, annot=True)\n",
    "plt.title('Confusion Matrix')\n",
    "plt.ylabel('Actal Values')\n",
    "plt.xlabel('Predicted Values')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>140</th>\n",
       "      <th>141</th>\n",
       "      <th>142</th>\n",
       "      <th>143</th>\n",
       "      <th>144</th>\n",
       "      <th>145</th>\n",
       "      <th>146</th>\n",
       "      <th>147</th>\n",
       "      <th>148</th>\n",
       "      <th>149</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000356</td>\n",
       "      <td>0.005772</td>\n",
       "      <td>-0.001165</td>\n",
       "      <td>0.227009</td>\n",
       "      <td>0.210234</td>\n",
       "      <td>0.046924</td>\n",
       "      <td>-0.160775</td>\n",
       "      <td>0.056280</td>\n",
       "      <td>-0.062349</td>\n",
       "      <td>0.088247</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.169635</td>\n",
       "      <td>-0.155996</td>\n",
       "      <td>0.254140</td>\n",
       "      <td>-0.182927</td>\n",
       "      <td>-0.140719</td>\n",
       "      <td>-0.136848</td>\n",
       "      <td>-0.188922</td>\n",
       "      <td>0.070345</td>\n",
       "      <td>0.341330</td>\n",
       "      <td>-0.286320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000726</td>\n",
       "      <td>0.001762</td>\n",
       "      <td>0.000045</td>\n",
       "      <td>-0.045303</td>\n",
       "      <td>-0.216565</td>\n",
       "      <td>0.017450</td>\n",
       "      <td>0.248907</td>\n",
       "      <td>-0.070705</td>\n",
       "      <td>0.029402</td>\n",
       "      <td>-0.039797</td>\n",
       "      <td>...</td>\n",
       "      <td>0.201839</td>\n",
       "      <td>0.194292</td>\n",
       "      <td>-0.203493</td>\n",
       "      <td>0.196752</td>\n",
       "      <td>0.160361</td>\n",
       "      <td>-0.038499</td>\n",
       "      <td>0.197765</td>\n",
       "      <td>-0.015678</td>\n",
       "      <td>-0.312534</td>\n",
       "      <td>-0.292287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.001082</td>\n",
       "      <td>-0.007534</td>\n",
       "      <td>0.001120</td>\n",
       "      <td>-0.181706</td>\n",
       "      <td>0.006331</td>\n",
       "      <td>-0.064374</td>\n",
       "      <td>-0.088132</td>\n",
       "      <td>0.014425</td>\n",
       "      <td>0.032947</td>\n",
       "      <td>-0.048451</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.032205</td>\n",
       "      <td>-0.038296</td>\n",
       "      <td>-0.050647</td>\n",
       "      <td>-0.013825</td>\n",
       "      <td>-0.019642</td>\n",
       "      <td>0.175347</td>\n",
       "      <td>-0.008843</td>\n",
       "      <td>-0.054667</td>\n",
       "      <td>-0.028796</td>\n",
       "      <td>0.578607</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 150 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        0         1         2         3         4         5         6    \\\n",
       "0  0.000356  0.005772 -0.001165  0.227009  0.210234  0.046924 -0.160775   \n",
       "1  0.000726  0.001762  0.000045 -0.045303 -0.216565  0.017450  0.248907   \n",
       "2 -0.001082 -0.007534  0.001120 -0.181706  0.006331 -0.064374 -0.088132   \n",
       "\n",
       "        7         8         9    ...       140       141       142       143  \\\n",
       "0  0.056280 -0.062349  0.088247  ... -0.169635 -0.155996  0.254140 -0.182927   \n",
       "1 -0.070705  0.029402 -0.039797  ...  0.201839  0.194292 -0.203493  0.196752   \n",
       "2  0.014425  0.032947 -0.048451  ... -0.032205 -0.038296 -0.050647 -0.013825   \n",
       "\n",
       "        144       145       146       147       148       149  \n",
       "0 -0.140719 -0.136848 -0.188922  0.070345  0.341330 -0.286320  \n",
       "1  0.160361 -0.038499  0.197765 -0.015678 -0.312534 -0.292287  \n",
       "2 -0.019642  0.175347 -0.008843 -0.054667 -0.028796  0.578607  \n",
       "\n",
       "[3 rows x 150 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(logis.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>intercept</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.0</td>\n",
       "      <td>-0.041455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.0</td>\n",
       "      <td>0.040948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.0</td>\n",
       "      <td>0.000507</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   class  intercept\n",
       "0    3.0  -0.041455\n",
       "1    4.0   0.040948\n",
       "2    5.0   0.000507"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame({\"class\": logis.classes_, \"intercept\":logis.intercept_})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "62     0.014224\n",
       "2      0.014116\n",
       "18     0.010706\n",
       "65     0.008744\n",
       "133    0.008318\n",
       "40     0.008162\n",
       "91     0.007941\n",
       "21     0.007583\n",
       "48     0.007502\n",
       "0      0.007496\n",
       "dtype: float64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_selection import mutual_info_classif\n",
    "mutual_inf = pd.Series(mutual_info_classif(train_X, train_y, discrete_features=[\"publisher\" in name for name in train_X.columns]))\n",
    "mutual_inf.nlargest(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_X = pd.read_csv(\"predict_final.csv\")\n",
    "predictions = pd.Series(logis.predict(predict_X))\n",
    "csv_file = pd.DataFrame(predictions, columns=[label])\n",
    "csv_file.insert(0, \"id\", predictions.index + 1)\n",
    "csv_file.to_csv(\"logistic_output.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
